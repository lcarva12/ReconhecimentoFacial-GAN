# Reconhecimento facial em risco: Vulnerabilidades e defesas contra ataques adversariais.

Feito por: 
  - Gabriela Cristina Moreira dos Santos RA 156406
  - Lucas Guilherme Carvalho RA 156556

Esta arquivo possui as atividades da Disciplina de IA-Unifesp-2023

Este estudo se concentra na compreensão dos ataques adversariais em sistemas de reconhecimento facial baseados em Inteligência Artificial (IA) e na implementação de estratégias de defesa. Os sistemas de reconhecimento facial, muitas vezes baseados em aprendizado profundo e redes neurais artificiais, são susceptíveis a ataques adversariais que envolvem perturbações quase imperceptíveis inseridas nas imagens de entrada. A metodologia empregada abrange uma revisão extensa da literatura, análise de conjuntos de dados de imagens de rosto para treinar e testar modelos, e a avaliação de diferentes abordagens de detecção e defesa. Os modelos são treinados utilizando técnicas de aprendizado profundo e, em seguida, são testados sob diversas condições, incluindo ataques adversariais. Variadas estratégias de defesa contra esses ataques são implementadas e testadas, com seus resultados subsequentemente analisados. Além disso, o estudo também procura incentivar a colaboração na área de segurança em IA, de forma a enfrentar os desafios associados aos ataques adversariais.

Video com a Prévia sobre o Tema:
  - [Reconhecimento Facial em Risco](https://youtu.be/B_FHYxX5KbA)
  - [Apresentação utilizada](https://docs.google.com/presentation/d/1-N27UrFtbKMgUryNtCJmzJuAVPuQGNPea0_kqn5h-6E/edit#slide=id.p)

Dados:
  Os dados utilizados são do [Dataset LFW](http://vis-www.cs.umass.edu/lfw/), O Download pode ser feito [aqui](http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz)
